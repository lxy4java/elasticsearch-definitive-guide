[[configuring-language-analyzers]]
=== 配置各种语言分析器


各语言分词器们都不需要任何配置开箱即用， ((("english analyzer", "configuring")))
((("language analyzers", "configuring")))它们中大部分都允许你明确他们的行为：

[[stem-exclusion]]
切词干扰::
+
想象下，某个场景，用户们想要搜索((("language analyzers", "configuring", "stem word exclusion")))
((("stemming words", "stem word exclusion, configuring"))) “World Health Organization” 的结果，
但是却被替换为搜索 “organ health.” 的结果。有这个困惑的原因是因为“organ”和“organization”
有相同的词根：`organ`。通常这不是什么大问题，但是在一些特殊的文档中就会导致有歧义的结果，
所以我们得防止单词 `organization` 和 `organizations` 被切分为词根

常用停用词::
英语中默认的停用词列表如下：
+
    a, an, and, are, as, at, be, but, by, for, if, in, into, is, it,
    no, not, of, on, or, such, that, the, their, then, there, these,
    they, this, to, was, will, with
+
关于单词 `no` 和 `not` 有件不合理的事，这俩词会反转跟在它们后面的词汇的含义。或许我们应该认为这俩词很重要，不应该把他们看成停词。


为了自定义 `english`（英语）分词器的行为，我们需要基于 `english`（英语）分词器创建一个自定义分词器，然后添加一些配置：


[source,js]
--------------------------------------------------
PUT /my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_english": {
          "type": "english",
          "stem_exclusion": [ "organization", "organizations" ], <1>
          "stopwords": [ <2>
            "a", "an", "and", "are", "as", "at", "be", "but", "by", "for",
            "if", "in", "into", "is", "it", "of", "on", "or", "such", "that",
            "the", "their", "then", "there", "these", "they", "this", "to",
            "was", "will", "with"
          ]
        }
      }
    }
  }
}

GET /my_index/_analyze?analyzer=my_english <3>
The World Health Organization does not sell organs.
--------------------------------------------------
<1> 防止 `organization` 和 `organizations` 被切为词根
<2> 指定一个自定义停词列表
<3> 切词为 `world`, `health`, `organization`, `does`, `not`, `sell`, `organ`


我们在<<stemming>>和<<stopwords>>中详细讨论了切词寻根和停词。
