[[configuring-language-analyzers]]
=== 配置各种语言分析器


各语言分析器们都不需要任何配置开箱即用， ((("english analyzer", "configuring")))
((("language analyzers", "configuring")))它们中的大多数都允许你控制它们的各方面行为，具体来说：

[[stem-exclusion]]
切词干扰::
+
想象下，某个场景，用户们想要搜索((("language analyzers", "configuring", "stem word exclusion")))
((("stemming words", "stem word exclusion, configuring"))) `'World Health Organization'` 的结果，
但是却被替换为搜索 `'organ health.'` 的结果。有这个困惑的原因是因为 `'organ'` 和 `'organization'`
有相同的词根：`organ`。通常这不是什么大问题，但是在一些特殊的文档中就会导致有歧义的结果，
所以我们得防止单词 `organization` 和 `organizations` 被切分为词根

自定义停用词::

英语中默认的停用词列表如下：((("stopwords", "configuring for language analyzers")))
+
    a, an, and, are, as, at, be, but, by, for, if, in, into, is, it,
    no, not, of, on, or, such, that, the, their, then, there, these,
    they, this, to, was, will, with
+
关于单词 `no` 和 `not` 有点特别，这俩词会反转跟在它们后面的词汇的含义。或许我们应该认为这俩词很重要，不应该把他们看成停词。


为了自定义 `english`（英语）分词器的行为，我们需要基于 `english`（英语）分析器创建一个自定义分析器，然后添加一些配置：


[source,js]
--------------------------------------------------
PUT /my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_english": {
          "type": "english",
          "stem_exclusion": [ "organization", "organizations" ], <1>
          "stopwords": [ <2>
            "a", "an", "and", "are", "as", "at", "be", "but", "by", "for",
            "if", "in", "into", "is", "it", "of", "on", "or", "such", "that",
            "the", "their", "then", "there", "these", "they", "this", "to",
            "was", "will", "with"
          ]
        }
      }
    }
  }
}

GET /my_index/_analyze?analyzer=my_english <3>
The World Health Organization does not sell organs.
--------------------------------------------------
<1> 防止 `organization` 和 `organizations` 被切为词根
<2> 指定一个自定义停用词列表
<3> 切词为 `world`, `health`, `organization`, `does`, `not`, `sell`, `organ`


我们在<<stemming>>和<<stopwords>>中分别详细讨论了词干提取和停用词。
